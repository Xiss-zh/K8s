



# Kubeadm安装K8s_V1.23.xx：Docker

## 一、系统基础环境配置

### 0、版本信息

```shell
OS：CentOS Linux release 7.9-2207-2
内核：建议4.19以上，不升级也可以，主要影响后期不能使用cephfs文件系统
K8s-Version： 1.23.15
```



### 1、配置主机名与解析

```shell
# 配置主机名
hostnamectl set-hostname k8s-master01

# 配置域名解析
cat >> /etc/hosts << EOF

192.168.10.200 k8s-master   #vip
192.168.10.231 k8s-master01
192.168.10.232 k8s-master02
192.168.10.233 k8s-master03
192.168.10.236 k8s-node01
192.168.10.237 k8s-node02
192.168.10.238 k8s-node03

EOF
```

### 2、关闭防火墙与selinux

```shell
# 关闭防火墙
systemctl stop firewalld && systemctl disable firewalld

# 关闭selinux
setenforce 0 && sed -ri 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
```

### 3、禁用swap交换机空间

```shell
# 关闭与禁用swap交换空间
swapoff -a && sed -ri 's/.*swap.*/#&/' /etc/fstab

```

![image-20230426110048962](D:\GitHub\K8s\png\image-20230426110048962.png)

![image-20230504115908016](D:\Github\K8s\png\image-20230504115908016.png)

```shell
# 删除swap卷
lvdisplay
lvremove /dev/centos/swap

# 将空闲磁盘扩容到根目录
vgdisplay
lvextend -l +xxx /dev/centos/root
xfs_growfs /dev/centos/root
```

![image-20230504120055988](D:\Github\K8s\png\image-20230504120055988.png)

![image-20230504120413246](D:\Github\K8s\png\image-20230504120413246.png)

```shell
#删除swap卷需要重新生成启动信息，若不生成，启动将会出问题
vim /etc/default/grub
grub2-mkconfig -o /boot/grub2/grub.cfg
```

![image-20230504133053943](D:\Github\K8s\png\image-20230504133053943.png)

![image-20230504133153943](D:\Github\K8s\png\image-20230504133153943.png)

### 4、配置时间同步

```shell
# 使用chrony时间同步
yum install chrony

# 增加时间国内时间同步源,并禁用默认时间同步源
vim /etc/chrony.conf

server ntp.aliyun.com iburst
server cn.ntp.org.cn iburst

#运行chrony服务并开机自启
systemctl enable chronyd --now

# 查看同步进度
chronyc sources –v

# 同步硬件时间
hwclock --show
hwclock --systohc
```

### 5、配置网络相关

```shell
# 使用network工具管理网络，禁用NetworkManager，会干扰容器网络
systemctl disable --now NetworkManager
```

### 6、配置k8s相关优化

```shell

# 加载k8s所需内核模块,用于将桥接流量转发至 iptables 链
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

lsmod | grep -e br_netfilter -e overlay

# 配置k8s优化所需的 sysctl 参数，参数在重新启动后保持不变
cat <<EOF > /etc/sysctl.d/k8s.conf

# 开启路由转发
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1

# 限制一个进程可以拥有的VMA(虚拟内存区域)的数量
vm.max_map_count = 262144

# 用于解决 K8S 内核软锁相关 bug
kernel.softlockup_panic = 1
kernel.softlockup_all_cpu_backtrace = 1

# 预留K8S默认端口
net.ipv4.ip_local_reserved_ports = 30000-32767

# 增加socket监听（listen）的backlog上限
net.core.somaxconn = 32768

# 接收套接字缓冲区大小的最大值
net.core.rmem_max = 16777216

# 发送套接字缓冲区大小的最大值
net.core.wmem_max = 16777216

# 增加总的可分配的 buffer 空间的最大值
net.ipv4.tcp_wmem = 4096 87380 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216

# 表示那些尚未收到客户端确认信息的连接（SYN消息）队列的长度，默认为1024，增加未完成的syn请求的数量
net.ipv4.tcp_max_syn_backlog = 8096

# 持久化 HTTP 连接
net.ipv4.tcp_slow_start_after_idle = 0

# 允许重用TIME_WAIT状态的套接字用于新的TCP连接,默认为0，表示关闭。
net.ipv4.tcp_tw_reuse = 1

# 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包，这个参数表示该队列的最大值
net.core.netdev_max_backlog = 16384

# 设置系统中所允许文件描述符的数量限制
fs.file-max = 1048576


# 一个用户的inotify实例和watch的最大数量，由于dockerd作为单个用户运行，每个用户的默认实例值128
fs.inotify.max_user_instances = 8192
fs.inotify.max_user_watches = 524288

# 对内存分配的一种策略，=1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何
vm.overcommit_memory = 1

# panic错误中自动重启，等待时间为10秒
kernel.panic = 10

# 在Oops发生时会进行panic()操作
kernel.panic_on_oops = 1

EOF


# 应用 sysctl 参数而不重新启动
sudo sysctl --system

```

### 7、安装并加载ipvs作为流量转发

```shell
# 安装ipvs
yum -y install ipvsadm 

# 清空规则
ipvsadm -l -n

# 设置ipvs模式，注意内核4.19前 nf_conntrack为 nf_conntrack_ipv4
cat <<EOF> /etc/sysconfig/modules/ipvs.modules
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
modprobe -- ip_tables
modprobe -- ip_set
modprobe -- xt_set
modprobe -- ipt_set
modprobe -- ipt_rpfilter
modprobe -- ipt_REJECT
modprobe -- ipip
EOF

chmod 755 /etc/sysconfig/modules/ipvs.modules
bash /etc/sysconfig/modules/ipvs.modules
lsmod | grep -e ip_vs -e nf_conntrack


# 清理iptables
iptables -F
iptables -X
```

### 8、安装Docker

```shell
# 安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。
 yum install -y yum-utils  device-mapper-persistent-data lvm2
 
# 设置为国内的阿里源地址：
 yum-config-manager --add-repo  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# 安装k8s兼容性20.10版本的Docker
yum install -y docker-ce-20.10.24 docker-ce-cli-20.10.24
 
# 设置开机自启并运行
systemctl enable --now docker
 
# 配置阿里镜像源，日志大小，cgroup
mkdir -p /etc/docker

cat > /etc/docker/daemon.json << EOF
{
  "registry-mirrors": ["https://b9pmyelo.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

# 加载配置文件重启
systemctl daemon-reload

# 重启
systemctl restart docker

# 查看docker 配置信息
docker info

```



## 二、k8s相关部署

### 1、安装kubelet、kubeadm、kubectl

```shell
# 配置阿里源
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# 安装kubelet、kubeadm、kubectl，版本为1.23.15
yum install -y kubelet-1.23.15  kubeadm-1.23.15  kubectl-1.23.15 --disableexcludes=kubernetes

# 设置开机自启
systemctl enable --now kubelet
```

### 2、配置命令补全

```shell
# 安装命令补全，启动 kubectl 自动补全功能
yum install -y bash-completion

kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl > /dev/null
sudo chmod a+r /etc/bash_completion.d/kubectl
```

### 3、配置镜像管理工具

```shell
# 默认ctr容器管理功能不全，使用k8s的容器管理工具
cat > /etc/crictl.yaml <<EOF
runtime-endpoint: unix:///var/run/containerd/containerd.sock
image-endpoint: unix:///var/run/containerd/containerd.sock
timeout: 10
debug: false
pull-image-on-create: false
EOF
```

### 4、下载阿里云k8s镜像

```shell
# 查看k8s需要下载的镜像
kubeadm config images list --kubernetes-version v1.25.9 --image-repository registry.aliyuncs.com/google_containers

# 提前下载镜像
tee ./images.sh <<'EOF'
#!/bin/bash

images=(
kube-apiserver:v1.25.9
kube-controller-manager:v1.25.9
kube-scheduler:v1.25.9
kube-proxy:v1.25.9
pause:3.8
etcd:3.5.6-0
coredns:v1.9.3
)
for imageName in ${images[@]} ; do
ctr images pull registry.aliyuncs.com/google_containers/$imageName
done
EOF

chmod +x ./images.sh && ./images.sh
```

### 5、初始化主节点

```shell
# 生成初始化配置，并根据实际情况修改
kubeadm config print init-defaults > kubeadm-init.yaml

vim kubeadm-init.yaml
```

```shell
apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
# 创建多master节点集群需注销
# localAPIEndpoint:
#   advertiseAddress: 1.2.3.4
#   bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  imagePullPolicy: IfNotPresent
#  name: node
  taints: null
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns: {}
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers     # 设置为阿里云镜像
kind: ClusterConfiguration
kubernetesVersion: 1.25.9     #设置版本
controlPlaneEndpoint: 192.168.10.231:6443    #增加配置，可设置为vip
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
  podSubnet: 10.244.0.0/16   # 增加pod-ip段
scheduler: {}

# 设置为ipvs模式，cgroup驱动为systemd
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
ipvs:
  minSyncPeriod: 1s
  scheduler: rr
  syncPeriod: 30s
mode: ipvs
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: systemd

```

```shell
# 初始化主节点
kubeadm init --config=kubeadm-init.yaml --ignore-preflight-errors=SystemVerification

```



### 6、配置管理权限

```shell
# 根据提示操作
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


# 查看集群状态，网络插件未安装节点状态是：NotReady
```

![image-20230427163414790](D:\GitHub\K8s\png\image-20230427163414790.png)



![image-20230426144031737](D:\GitHub\K8s\png\image-20230426144031737.png)

### 7、安装网络组件：flannel

```shell
# 特别注意，红帽相关系统需禁用NetworkManager，不然将会干扰pod直接的网络，比如ingress负载均衡，原本三个节点只有两个节点正常访问
wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

#修改ip地址
vim kube-flannel.yml
"Network": "10.244.0.0/16",

kubectl apply -f kube-flannel.yml
```

### 8、增加k8s节点

```shell
# 创建ssh密钥
ssh-keygen -t rsa
# 分发密钥到其它master节点
ssh-copy-id -i k8s-master02
```

![image-20230427162847947](D:\GitHub\K8s\png\image-20230427162847947.png)

#### 1) 新master节点操作

```shell
# 创建证书存放目录
mkdir -p /etc/kubernetes/pki/etcd
```

#### 2）旧master节点操作

```shell
# 查询加入集群token
kubeadm token create --print-join-command
# node节点直接通过如下命令加入k8s集群
```

![image-20230427164319777](D:\GitHub\K8s\png\image-20230427164319777.png)

```shell
# 复制证书到其它节点
scp /etc/kubernetes/pki/ca.* root@k8s-master02:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/sa.* root@k8s-master02:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/front-proxy-ca.* root@k8s-master02:/etc/kubernetes/pki/
scp /etc/kubernetes/pki/etcd/ca.* root@k8s-master02:/etc/kubernetes/pki/etcd/

```

#### 3) 新master节点加入集群

```shell
# 将查询到的加入集群tokgen，增加--control-plane参数，代表master节点
kubeadm join 192.168.10.231:6443 --token evdk7s.6g13l3eveutpijt6 \
--discovery-token-ca-cert-hash  sha256:e2ed7e638dcdbde3e04ff84714b4c32fa3f6cea86f7d9be620f48d150700996d \
--control-plane
```



## 三、部署ingress-nginx

### 1、访问k8s仓库，查看兼容性

```shell
# ingress-nginx仓库地址
https://github.com/kubernetes/ingress-nginx
```

![image-20230426151812103](D:\GitHub\K8s\png\image-20230426151812103.png)

```
wget  https://github.com/kubernetes/ingress-nginx/archive/refs/tags/controller-v1.4.0.tar.gz
tar -zxvf controller-v1.5.1.tar.gz

cd ./ingress-nginx-controller-v1.5.1/deploy/static/provider/baremetal


```



## 四、部署官方dashboard

### 1、部署dashboard容器

```shell
# 部署dashboard容器
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml
```

![image-20230426150308924](D:\GitHub\K8s\png\image-20230426150308924.png)

```shell
# 创建 dashboard-admin 用户
kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard
 
# 绑定 clusterrolebinding
kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin

```

```
# 创建token的Secret文件
cat >> dashboard-admin-token.yaml << EOF
apiVersion: v1
kind: Secret
metadata:
  name: dashboard-admin-secret
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/service-account.name: dashboard-admin
type: kubernetes.io/service-account-token

EOF
```

```shell
# 创建token
kubectl apply -f dashboard-admin-token.yaml
 
# 获取token
kubectl describe secret dashboard-admin-secret -n kubernetes-dashboard
```

![image-20230426150139262](D:\GitHub\K8s\png\image-20230426150139262.png)

```shell
# 创建dashboard的yum访问
cat >> dashboard-ingress.yaml << EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: k8s-dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/secure-backends: "true"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  tls:
    - hosts:
        - dashboard.xiss.com
      secretName: kubernetes-dashboard-certs
  rules:
    - host: dashboard.xiss.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: kubernetes-dashboard
                port:
                  number: 443

EOF
```



### 12、删除节点

```shell
#在master节上，执行：
kubectl drain 节点名 --delete-local-data --force --ignore-daemonsets

#从集群移出
kubectl delete node 节点名


#在node3机器上，执行：
kubeadm reset

#清除iptable规则
iptables -X
iptables -F
#或者运行
ipvsadm --clear

#删除cni相关配置
rm -rf /etc/cni/
```



### 13、重新添加master节点

```shell
mkdir -p /etc/kubernetes/pki/etcd
scp root@k8s-master01:/etc/kubernetes/pki/ca.crt /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/ca.key /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/sa.key /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/sa.pub /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/front-proxy-ca.crt /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/front-proxy-ca.key /etc/kubernetes/pki/
scp root@k8s-master01:/etc/kubernetes/pki/etcd/ca.crt /etc/kubernetes/pki/etcd/
scp root@k8s-master01:/etc/kubernetes/pki/etcd/ca.key /etc/kubernetes/pki/etcd/
scp root@k8s-master01:/etc/kubernetes/admin.conf /etc/kubernetes/admin.conf

#新令牌
kubeadm token create --print-join-command

kubeadm join k8s-master01:6443 --token 2jye4v.78x944oi00oel0z5 --discovery-token-ca-cert-hash sha256:01fba33fffab3e527e5a2b10f505f33489761b4d0c131bd84cf6f1fd9b0e8e23 --control-plane
```

14、查看添加节点的命令

```
kubeadm token create --print-join-command
```



### 14、生成100年证书

```
yum install gcc make -y
yum install jq -y

cat ./build/build-image/cross/VERSION
v1.25.0-go1.19.8-bullseye.0

wget https://dl.google.com/go/go1.19.8.linux-amd64.tar.gz
tar zxvf go1.19.8.linux-amd64.tar.gz -C /usr/local

export GOROOT=/usr/local/go
export PATH=$PATH:/usr/local/go/bin
export GOPATH=/go

git clone https://github.com/kubernetes/kubernetes.git
cd kubernetes/
git checkout v1.25.9

vim ./cmd/kubeadm/app/constants/constants.go
vim ./staging/src/k8s.io/client-go/util/cert/cert.go

make all WHAT=cmd/kubeadm GOFLAGS=-v

cp _output/bin/kubeadm /usr/bin/kubeadm




kubeadm certificates check-expiration
```

